{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYe8WmS1_9JP","outputId":"837db3bb-f8d4-4afe-bb59-82b5451ed9c8","executionInfo":{"status":"ok","timestamp":1748065709813,"user_tz":-420,"elapsed":29259,"user":{"displayName":"Thiên Ân Huỳnh","userId":"14778843526455010078"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89GLxrr6AzjZ"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","from sklearn.utils.class_weight import compute_class_weight\n","import pandas as pd\n","from collections import Counter\n","\n","classes = ['Aorta', 'Flows', 'Other', 'V sign', 'X sign']\n","\n","import os\n","import cv2\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","class FetalEchoDataset(Dataset):\n","    def __init__(self, root_dir, phase='train', transform=None, selected_classes=None, x_sign_mode='both'):\n","        self.root_dir = root_dir\n","        self.phase = phase\n","        self.transform = transform\n","\n","        all_classes = ['Aorta', 'Flows', 'Other', 'V sign', 'X sign']\n","        self.classes = selected_classes if selected_classes is not None else all_classes\n","        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n","        self.samples = []\n","\n","        if phase in ['train']:\n","            for cls in self.classes:\n","                if cls == 'X sign':\n","                    # Tùy chọn cách lấy ảnh của X sign\n","                    if x_sign_mode == 'clear':\n","                        subfolder = 'X sign/clear'\n","                        folder_path = os.path.join(root_dir, phase, subfolder)\n","                        if os.path.exists(folder_path):\n","                            for fname in os.listdir(folder_path):\n","                                if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                    full_path = os.path.join(folder_path, fname)\n","                                    self.samples.append((full_path, self.class_to_idx['X sign']))\n","                    elif x_sign_mode == 'deformed':\n","                        subfolder = 'X sign/deformed'\n","                        folder_path = os.path.join(root_dir, phase, subfolder)\n","                        if os.path.exists(folder_path):\n","                            for fname in os.listdir(folder_path):\n","                                if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                    full_path = os.path.join(folder_path, fname)\n","                                    self.samples.append((full_path, self.class_to_idx['X sign']))\n","                    elif x_sign_mode == 'both':\n","                        for subfolder in ['both']:\n","                            folder_path = os.path.join(root_dir, phase, 'X sign', subfolder)\n","                            if os.path.exists(folder_path):\n","                                for fname in os.listdir(folder_path):\n","                                    if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                        full_path = os.path.join(folder_path, fname)\n","                                        self.samples.append((full_path, self.class_to_idx['X sign']))\n","                else:\n","                    folder_path = os.path.join(root_dir, phase, cls)\n","                    if os.path.exists(folder_path):\n","                        for fname in os.listdir(folder_path):\n","                            if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                full_path = os.path.join(folder_path, fname)\n","                                self.samples.append((full_path, self.class_to_idx[cls]))\n","        elif phase in ['valid', 'test']:\n","            for cls in self.classes:\n","              folder_path = os.path.join(root_dir, phase, cls)\n","              if os.path.exists(folder_path):\n","                  for fname in os.listdir(folder_path):\n","                      if fname.endswith('.jpg') or fname.endswith('.png'):\n","                          full_path = os.path.join(folder_path, fname)\n","                          self.samples.append((full_path, self.class_to_idx[cls]))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.samples[idx]\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"No6-x28K8aj7"},"outputs":[],"source":["import torch\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","main_folder = '/content/drive/MyDrive/Colab Notebooks/dataset/processedfetal_delation'\n","# Set image size if needed (optional)\n","IMG_SIZE = (224, 224)\n","\n","# Data augmentations for training set\n","train_transforms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomHorizontalFlip(p=0.5),  # Flip ngang\n","    transforms.RandomApply([\n","        transforms.RandomRotation(degrees=10)  # Xoay ±10 độ\n","    ], p=0.75),\n","    transforms.RandomResizedCrop(size=IMG_SIZE, scale=(1.0, 1.1)),\n","    # Phóng to trong khoảng 1.0–1.1x và resize về IMG_SIZE\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Thay đổi sáng/tương phản\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Warp đối xứng\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa ảnh màu RGB\n","])\n","# For validation/test: no augmentation\n","val_test_transforms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa ảnh màu RGB\n","])\n","\n","# Chỉ dùng X sign rõ cấu trúc\n","train_dataset_clear = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='clear')\n","\n","# Hoặc chỉ dùng X sign biến dạng\n","train_dataset_deformed = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='deformed')\n","\n","# Hoặc dùng cả hai (mặc định)\n","train_dataset_both = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='both')\n","\n","\n","# Load datasets\n","valid_dataset = FetalEchoDataset(main_folder, phase='valid', transform=val_test_transforms)\n","test_dataset  = FetalEchoDataset(main_folder, phase='test',  transform=val_test_transforms)\n","\n","# DataLoaders\n","BATCH_SIZE = 32\n","train_dataset_both_loader = DataLoader(train_dataset_both, batch_size=BATCH_SIZE, shuffle=True)\n","train_dataset_deformed_loader =DataLoader(train_dataset_deformed, batch_size=BATCH_SIZE, shuffle=True)\n","train_dataset_clear_loader = DataLoader(train_dataset_clear, batch_size=BATCH_SIZE, shuffle=True)\n","\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0G-0gYMHUApy"},"outputs":[],"source":["# CBAM\n","class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=16):\n","        super().__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n","            nn.ReLU(),\n","            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n","        )\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc(self.avg_pool(x))\n","        max_out = self.fc(self.max_pool(x))\n","        return self.sigmoid(avg_out + max_out)\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super().__init__()\n","        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        return self.sigmoid(self.conv(x))\n","\n","class CBAM(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.ca = ChannelAttention(channels, reduction)\n","        self.sa = SpatialAttention()\n","\n","    def forward(self, x):\n","        return self.sa(self.ca(x) * x) * (self.ca(x) * x)\n","\n","# Model\n","from torchvision.models import DenseNet201_Weights\n","class DenseNet201_CBAM(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        base = models.densenet201(weights=DenseNet201_Weights.DEFAULT)\n","        self.features = base.features\n","        self.cbam1 = CBAM(256)\n","        self.cbam2 = CBAM(1792)\n","        self.cbam3 = CBAM(1920)\n","        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(1920, num_classes)\n","\n","    def forward(self, x):\n","        x = self.features.conv0(x)\n","        x = self.features.norm0(x)\n","        x = self.features.relu0(x)\n","        x = self.features.pool0(x)\n","\n","        x = self.features.denseblock1(x)\n","        x = self.cbam1(x)\n","        x = self.features.transition1(x)\n","\n","        x = self.features.denseblock2(x)\n","        x = self.features.transition2(x)\n","\n","        x = self.features.denseblock3(x)\n","        x = self.cbam2(x)\n","        x = self.features.transition3(x)\n","\n","        x = self.features.denseblock4(x)\n","        x = self.features.norm5(x)\n","        x = self.cbam3(x)\n","\n","        x = self.pool(x).view(x.size(0), -1)\n","        return self.fc(x)\n"]},{"cell_type":"code","source":["del"],"metadata":{"id":"woRSytdF5eKT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcqdXTK8B61o","outputId":"1d008124-7489-485f-d78b-780fa70610af","executionInfo":{"status":"ok","timestamp":1747845211542,"user_tz":-420,"elapsed":3408724,"user":{"displayName":"Thiên Ân Huỳnh","userId":"14778843526455010078"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Phase 1: Epoch 1: Train Loss = 0.4470, Val Loss = 0.3308, Acc = 0.9135, F1 Score(macro) = 0.8723 \n","✅ Saved best model!\n","Phase 1: Epoch 2: Train Loss = 0.0879, Val Loss = 0.2821, Acc = 0.9260, F1 Score(macro) = 0.8683 \n","Phase 1: Epoch 3: Train Loss = 0.0464, Val Loss = 0.2740, Acc = 0.9268, F1 Score(macro) = 0.8629 \n","Phase 1: Epoch 4: Train Loss = 0.0282, Val Loss = 0.4139, Acc = 0.8979, F1 Score(macro) = 0.8079 \n","Phase 1: Epoch 5: Train Loss = 0.0322, Val Loss = 0.2698, Acc = 0.9253, F1 Score(macro) = 0.8734 \n","✅ Saved best model!\n","Phase 1: Epoch 6: Train Loss = 0.0194, Val Loss = 0.2337, Acc = 0.9290, F1 Score(macro) = 0.8664 \n","Phase 1: Epoch 7: Train Loss = 0.0234, Val Loss = 0.2824, Acc = 0.9534, F1 Score(macro) = 0.9026 \n","✅ Saved best model!\n","Phase 1: Epoch 8: Train Loss = 0.0226, Val Loss = 0.2058, Acc = 0.9445, F1 Score(macro) = 0.9114 \n","✅ Saved best model!\n","Phase 1: Epoch 9: Train Loss = 0.0070, Val Loss = 0.2636, Acc = 0.9445, F1 Score(macro) = 0.8967 \n","Phase 1: Epoch 10: Train Loss = 0.0075, Val Loss = 0.3175, Acc = 0.9349, F1 Score(macro) = 0.8707 \n"]}],"source":["# Focal Loss with class weights\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.ce = nn.CrossEntropyLoss(reduction='none')\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = self.ce(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce_loss\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce_loss\n","        return loss.mean()\n","# Device & training\n","best_f1 = 0.0\n","pathbestmodel = ''\n","from sklearn.metrics import f1_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DenseNet201_CBAM(num_classes=len(classes)).to(device)\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","train_losses, valid_losses, accuracies = [], [], []\n","num_epochs = 10\n","count=0\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_dataset_clear_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","    epoch_loss = running_loss / len(train_dataset_clear_loader.dataset)\n","    train_losses.append(epoch_loss)\n","\n","    model.eval()\n","    valid_loss, correct = 0.0, 0\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    valid_epoch_loss = valid_loss / len(valid_loader.dataset)\n","    accuracy = correct.double() / len(valid_loader.dataset)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","    valid_losses.append(valid_epoch_loss)\n","    accuracies.append(accuracy.item())\n","\n","    print(f\"Phase 1: Epoch {epoch+1}: Train Loss = {epoch_loss:.4f}, Val Loss = {valid_epoch_loss:.4f}, Acc = {accuracy:.4f}, F1 Score(macro) = {f1:.4f} \")\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        pathbestmodel = f'/content/drive/MyDrive/Colab Notebooks/model/model_test/Densenet_CBAM_with_Xsign_clear{count}.pt'\n","        torch.save(model.state_dict(), pathbestmodel)\n","        count += 1\n","        print(\"✅ Saved best model!\")"]},{"cell_type":"code","source":["# Focal Loss with class weights\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        self.ce = nn.CrossEntropyLoss(reduction='none')\n","\n","    def forward(self, inputs, targets):\n","        ce_loss = self.ce(inputs, targets)\n","        pt = torch.exp(-ce_loss)\n","        if self.alpha is not None:\n","            at = self.alpha[targets]\n","            loss = at * (1 - pt) ** self.gamma * ce_loss\n","        else:\n","            loss = (1 - pt) ** self.gamma * ce_loss\n","        return loss.mean()"],"metadata":{"id":"grM2Lpiv9NfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Device & training\n","best_f1 = 0.9114\n","from sklearn.metrics import f1_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DenseNet201_CBAM(num_classes=len(classes)).to(device)\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-Rm8urA86cy","executionInfo":{"status":"ok","timestamp":1747961236559,"user_tz":-420,"elapsed":1217,"user":{"displayName":"Ánh Nguyễn Thị","userId":"04851717377834282482"}},"outputId":"45434e70-bd2e-4b0e-86fd-f690ef976a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n","100%|██████████| 77.4M/77.4M [00:00<00:00, 184MB/s]\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def distillation_loss(student_logits, teacher_logits, T=2.0):\n","    student_soft = F.log_softmax(student_logits / T, dim=1)\n","    teacher_soft = F.softmax(teacher_logits / T, dim=1)\n","    loss = F.kl_div(student_soft, teacher_soft, reduction='batchmean') * (T * T)\n","    return loss"],"metadata":{"id":"6eX7MCs1fyd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy"],"metadata":{"id":"Jq_2M9VVf0Ve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pathbestmodel = '/content/drive/MyDrive/Colab Notebooks/model/model_test/Densenet_CBAM_with_Xsign_clear3.pt'"],"metadata":{"id":"ZfKo0Kwg8po6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(pathbestmodel))\n","model.eval()\n","# lưu model cũ\n","pathbestmodel_old = pathbestmodel\n","# Load lại mô hình phase 1 làm old_model (nếu chưa có)\n","old_model = copy.deepcopy(model)\n","old_model.eval()\n","for param in old_model.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"JoXiYRoxf6Ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#phase 2 version 3 thay đổi bot -> deformed loss = 40 mới +60 cũ\n","lambda_distill = 0.6\n","num_epochs = 10\n","count = 0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct_train, total_train = 0.0, 0, 0\n","\n","    for inputs, labels in train_dataset_deformed_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","\n","        with torch.no_grad():\n","            teacher_outputs = old_model(inputs)\n","\n","        loss_focal = criterion(outputs, labels)\n","        loss_distill = distillation_loss(outputs, teacher_outputs, T=2.0)\n","        loss = loss_focal + lambda_distill * loss_distill\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","    epoch_loss = running_loss / len(train_dataset_deformed_loader.dataset)\n","    train_acc = correct_train / total_train\n","\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(train_acc)\n","\n","\n","    # Đánh giá\n","    model.eval()\n","    valid_loss, correct = 0.0, 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    valid_epoch_loss = valid_loss / len(valid_loader.dataset)\n","    accuracy = correct.double() / len(valid_loader.dataset)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","    valid_losses.append(valid_epoch_loss)\n","    valid_accuracies.append(accuracy.item())\n","\n","    print(f\"Epoch {epoch+1}: \"\n","          f\"Train Loss = {epoch_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n","          f\"Val Loss = {valid_epoch_loss:.4f}, Val Acc = {accuracy:.4f}, \"\n","          f\"F1 Score (macro) = {f1:.4f}\")\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        pathbestmodel = f'/content/drive/MyDrive/Colab Notebooks/model/model_test/Densenet_CBAM_with_Xsign_deformed{count}.pt'\n","        torch.save(model.state_dict(), pathbestmodel)\n","        count += 1\n","        print(\"✅ Saved best model!\")\n"],"metadata":{"id":"J4uHnESsgWv7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747966728845,"user_tz":-420,"elapsed":5473349,"user":{"displayName":"Ánh Nguyễn Thị","userId":"04851717377834282482"}},"outputId":"44e0efb1-b7fc-499a-f441-8c90e410eca6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss = 0.0878, Train Acc = 0.9914, Val Loss = 0.1538, Val Acc = 0.9467, F1 Score (macro) = 0.9159\n","✅ Saved best model!\n","Epoch 2: Train Loss = 0.0974, Train Acc = 0.9904, Val Loss = 0.1860, Val Acc = 0.9475, F1 Score (macro) = 0.9123\n","Epoch 3: Train Loss = 0.0650, Train Acc = 0.9940, Val Loss = 0.1588, Val Acc = 0.9534, F1 Score (macro) = 0.9130\n","Epoch 4: Train Loss = 0.0553, Train Acc = 0.9958, Val Loss = 0.1579, Val Acc = 0.9593, F1 Score (macro) = 0.9287\n","✅ Saved best model!\n","Epoch 5: Train Loss = 0.0457, Train Acc = 0.9969, Val Loss = 0.1698, Val Acc = 0.9519, F1 Score (macro) = 0.9182\n","Epoch 6: Train Loss = 0.0390, Train Acc = 0.9982, Val Loss = 0.1630, Val Acc = 0.9549, F1 Score (macro) = 0.9263\n","Epoch 7: Train Loss = 0.0456, Train Acc = 0.9977, Val Loss = 0.1849, Val Acc = 0.9578, F1 Score (macro) = 0.9243\n","Epoch 8: Train Loss = 0.0676, Train Acc = 0.9927, Val Loss = 0.1871, Val Acc = 0.9593, F1 Score (macro) = 0.9254\n","Epoch 9: Train Loss = 0.0498, Train Acc = 0.9956, Val Loss = 0.1522, Val Acc = 0.9519, F1 Score (macro) = 0.9257\n","Epoch 10: Train Loss = 0.0405, Train Acc = 0.9982, Val Loss = 0.1459, Val Acc = 0.9519, F1 Score (macro) = 0.9191\n"]}]},{"cell_type":"code","source":["del model\n","del old_model"],"metadata":{"id":"B6QxENuX_8Sj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from sklearn.metrics import f1_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DenseNet201_CBAM(num_classes=len(classes)).to(device)\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"],"metadata":{"id":"8xr1sxnA_-t_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(pathbestmodel))\n","model.eval()\n","# lưu model cũ\n","pathbestmodel_old = pathbestmodel\n","# Load lại mô hình phase 1 làm old_model (nếu chưa có)\n","old_model = copy.deepcopy(model)\n","old_model.eval()\n","for param in old_model.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"RDXHkd6f_ypM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#phase 3\n","lambda_distill = 0.6\n","num_epochs = 10\n","count = 0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct_train, total_train = 0.0, 0, 0\n","\n","    for inputs, labels in train_dataset_both_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","\n","        with torch.no_grad():\n","            teacher_outputs = old_model(inputs)\n","\n","        loss_focal = criterion(outputs, labels)\n","        loss_distill = distillation_loss(outputs, teacher_outputs, T=2.0)\n","        loss = loss_focal + lambda_distill * loss_distill\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","    epoch_loss = running_loss / len(train_dataset_both_loader.dataset)\n","    train_acc = correct_train / total_train\n","\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(train_acc)\n","\n","\n","    # Đánh giá\n","    model.eval()\n","    valid_loss, correct = 0.0, 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    valid_epoch_loss = valid_loss / len(valid_loader.dataset)\n","    accuracy = correct.double() / len(valid_loader.dataset)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","    valid_losses.append(valid_epoch_loss)\n","    valid_accuracies.append(accuracy.item())\n","\n","    print(f\"Epoch {epoch+1}: \"\n","          f\"Train Loss = {epoch_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n","          f\"Val Loss = {valid_epoch_loss:.4f}, Val Acc = {accuracy:.4f}, \"\n","          f\"F1 Score (macro) = {f1:.4f}\")\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        pathbestmodel = f'/content/drive/MyDrive/Colab Notebooks/model/model_test/Densenet_CBAM_with_Xsign_both{count}.pt'\n","        torch.save(model.state_dict(), pathbestmodel)\n","        count += 1\n","        print(\"✅ Saved best model!\")\n"],"metadata":{"id":"Kh7zWK8eAEBS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747969554010,"user_tz":-420,"elapsed":1894097,"user":{"displayName":"Ánh Nguyễn Thị","userId":"04851717377834282482"}},"outputId":"781e6e94-b49d-4c40-bce5-698e7852503e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss = 0.0570, Train Acc = 0.9925, Val Loss = 0.1605, Val Acc = 0.9556, F1 Score (macro) = 0.9229\n","Epoch 2: Train Loss = 0.0460, Train Acc = 0.9947, Val Loss = 0.1710, Val Acc = 0.9593, F1 Score (macro) = 0.9319\n","✅ Saved best model!\n","Epoch 3: Train Loss = 0.0440, Train Acc = 0.9960, Val Loss = 0.1764, Val Acc = 0.9527, F1 Score (macro) = 0.9173\n","Epoch 4: Train Loss = 0.0302, Train Acc = 0.9977, Val Loss = 0.1649, Val Acc = 0.9541, F1 Score (macro) = 0.9239\n","Epoch 5: Train Loss = 0.0302, Train Acc = 0.9980, Val Loss = 0.1856, Val Acc = 0.9512, F1 Score (macro) = 0.9155\n","Epoch 6: Train Loss = 0.0277, Train Acc = 0.9972, Val Loss = 0.1732, Val Acc = 0.9556, F1 Score (macro) = 0.9237\n","Epoch 7: Train Loss = 0.0210, Train Acc = 0.9995, Val Loss = 0.1719, Val Acc = 0.9549, F1 Score (macro) = 0.9223\n","Epoch 8: Train Loss = 0.0231, Train Acc = 0.9982, Val Loss = 0.1586, Val Acc = 0.9534, F1 Score (macro) = 0.9195\n","Epoch 9: Train Loss = 0.0708, Train Acc = 0.9895, Val Loss = 0.2266, Val Acc = 0.9186, F1 Score (macro) = 0.8793\n","Epoch 10: Train Loss = 0.0917, Train Acc = 0.9880, Val Loss = 0.1752, Val Acc = 0.9556, F1 Score (macro) = 0.9223\n"]}]},{"cell_type":"code","source":["#phase 3\n","lambda_distill = 0.6\n","num_epochs = 10\n","count = 0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","alpha_weights = torch.tensor([1.2, 1.0, 2.5, 1.2, 3.0], dtype=torch.float32).to(device)\n","criterion = FocalLoss(alpha=alpha_weights)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct_train, total_train = 0.0, 0, 0\n","\n","    for inputs, labels in train_dataset_both_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","\n","        with torch.no_grad():\n","            teacher_outputs = old_model(inputs)\n","\n","        loss_focal = criterion(outputs, labels)\n","        loss_distill = distillation_loss(outputs, teacher_outputs, T=2.0)\n","        loss = loss_focal + lambda_distill * loss_distill\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","    epoch_loss = running_loss / len(train_dataset_both_loader.dataset)\n","    train_acc = correct_train / total_train\n","\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(train_acc)\n","\n","\n","    # Đánh giá\n","    model.eval()\n","    valid_loss, correct = 0.0, 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    valid_epoch_loss = valid_loss / len(valid_loader.dataset)\n","    accuracy = correct.double() / len(valid_loader.dataset)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","    valid_losses.append(valid_epoch_loss)\n","    valid_accuracies.append(accuracy.item())\n","\n","    print(f\"Epoch {epoch+1}: \"\n","          f\"Train Loss = {epoch_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n","          f\"Val Loss = {valid_epoch_loss:.4f}, Val Acc = {accuracy:.4f}, \"\n","          f\"F1 Score (macro) = {f1:.4f}\")\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        pathbestmodel = f'/content/drive/MyDrive/Colab Notebooks/model/model_test/Densenet_CBAM_with_Xsign_both{count}.pt'\n","        torch.save(model.state_dict(), pathbestmodel)\n","        count += 1\n","        print(\"✅ Saved best model!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-29R-j0MbjI","executionInfo":{"status":"ok","timestamp":1747972965831,"user_tz":-420,"elapsed":1896904,"user":{"displayName":"Ánh Nguyễn Thị","userId":"04851717377834282482"}},"outputId":"c6a5e032-ce21-460c-b116-9aff4d5f6734"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss = 0.0406, Train Acc = 0.9960, Val Loss = 0.1800, Val Acc = 0.9593, F1 Score (macro) = 0.9257\n","Epoch 2: Train Loss = 0.0281, Train Acc = 0.9992, Val Loss = 0.1551, Val Acc = 0.9601, F1 Score (macro) = 0.9333\n","✅ Saved best model!\n","Epoch 3: Train Loss = 0.0202, Train Acc = 0.9992, Val Loss = 0.1492, Val Acc = 0.9578, F1 Score (macro) = 0.9299\n","Epoch 4: Train Loss = 0.0368, Train Acc = 0.9960, Val Loss = 0.2034, Val Acc = 0.9578, F1 Score (macro) = 0.9313\n","Epoch 5: Train Loss = 0.0336, Train Acc = 0.9972, Val Loss = 0.2338, Val Acc = 0.9534, F1 Score (macro) = 0.9215\n","Epoch 6: Train Loss = 0.0337, Train Acc = 0.9965, Val Loss = 0.2082, Val Acc = 0.9519, F1 Score (macro) = 0.9176\n","Epoch 7: Train Loss = 0.0218, Train Acc = 0.9982, Val Loss = 0.1374, Val Acc = 0.9667, F1 Score (macro) = 0.9430\n","✅ Saved best model!\n","Epoch 8: Train Loss = 0.0166, Train Acc = 0.9992, Val Loss = 0.1668, Val Acc = 0.9601, F1 Score (macro) = 0.9300\n","Epoch 9: Train Loss = 0.0153, Train Acc = 0.9997, Val Loss = 0.1340, Val Acc = 0.9660, F1 Score (macro) = 0.9462\n","✅ Saved best model!\n","Epoch 10: Train Loss = 0.0150, Train Acc = 0.9992, Val Loss = 0.1274, Val Acc = 0.9667, F1 Score (macro) = 0.9478\n","✅ Saved best model!\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"WRRpyTbNoKkh","executionInfo":{"status":"ok","timestamp":1752222976776,"user_tz":-420,"elapsed":248,"user":{"displayName":"Thiên Ân Huỳnh","userId":"14778843526455010078"}},"outputId":"f5558aa7-f83a-4059-a8d9-d6bf24d2ad2c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Jul 11 08:36:16 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1_AmhJ9iiL-TQbVhJN-P72q4ddaf7QsjZ","timestamp":1747556476854}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}