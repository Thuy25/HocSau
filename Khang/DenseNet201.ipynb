{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27938,"status":"ok","timestamp":1747960827071,"user":{"displayName":"Quyền Huỳnh Minh","userId":"18408894874296736455"},"user_tz":-420},"id":"xYe8WmS1_9JP","outputId":"9937edee-432a-4782-8a5f-6d0dd99edc94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89GLxrr6AzjZ"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","from sklearn.utils.class_weight import compute_class_weight\n","import pandas as pd\n","from collections import Counter\n","\n","classes = ['Aorta', 'Flows', 'Other', 'V sign', 'X sign']\n","\n","import os\n","import cv2\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","class FetalEchoDataset(Dataset):\n","    def __init__(self, root_dir, phase='train', transform=None, selected_classes=None, x_sign_mode='both'):\n","        self.root_dir = root_dir\n","        self.phase = phase\n","        self.transform = transform\n","\n","        all_classes = ['Aorta', 'Flows', 'Other', 'V sign', 'X sign']\n","        self.classes = selected_classes if selected_classes is not None else all_classes\n","        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n","        self.samples = []\n","\n","        if phase in ['train']:\n","            for cls in self.classes:\n","                if cls == 'X sign':\n","                    # Tùy chọn cách lấy ảnh của X sign\n","                    if x_sign_mode == 'clear':\n","                        subfolder = 'X sign/clear'\n","                        folder_path = os.path.join(root_dir, phase, subfolder)\n","                        if os.path.exists(folder_path):\n","                            for fname in os.listdir(folder_path):\n","                                if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                    full_path = os.path.join(folder_path, fname)\n","                                    self.samples.append((full_path, self.class_to_idx['X sign']))\n","                    elif x_sign_mode == 'deformed':\n","                        subfolder = 'X sign/deformed'\n","                        folder_path = os.path.join(root_dir, phase, subfolder)\n","                        if os.path.exists(folder_path):\n","                            for fname in os.listdir(folder_path):\n","                                if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                    full_path = os.path.join(folder_path, fname)\n","                                    self.samples.append((full_path, self.class_to_idx['X sign']))\n","                    elif x_sign_mode == 'both':\n","                        for subfolder in ['both']:\n","                            folder_path = os.path.join(root_dir, phase, 'X sign', subfolder)\n","                            if os.path.exists(folder_path):\n","                                for fname in os.listdir(folder_path):\n","                                    if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                        full_path = os.path.join(folder_path, fname)\n","                                        self.samples.append((full_path, self.class_to_idx['X sign']))\n","                else:\n","                    folder_path = os.path.join(root_dir, phase, cls)\n","                    if os.path.exists(folder_path):\n","                        for fname in os.listdir(folder_path):\n","                            if fname.endswith('.jpg') or fname.endswith('.png'):\n","                                full_path = os.path.join(folder_path, fname)\n","                                self.samples.append((full_path, self.class_to_idx[cls]))\n","        elif phase in ['valid', 'test']:\n","            for cls in self.classes:\n","              folder_path = os.path.join(root_dir, phase, cls)\n","              if os.path.exists(folder_path):\n","                  for fname in os.listdir(folder_path):\n","                      if fname.endswith('.jpg') or fname.endswith('.png'):\n","                          full_path = os.path.join(folder_path, fname)\n","                          self.samples.append((full_path, self.class_to_idx[cls]))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.samples[idx]\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"No6-x28K8aj7"},"outputs":[],"source":["import torch\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","main_folder = '/content/drive/MyDrive/Colab Notebooks/dataset/processedfetal_delation'\n","# Set image size if needed (optional)\n","IMG_SIZE = (224, 224)\n","\n","# Data augmentations for training set\n","train_transforms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomHorizontalFlip(p=0.5),  # Flip ngang\n","    transforms.RandomApply([\n","        transforms.RandomRotation(degrees=10)  # Xoay ±10 độ\n","    ], p=0.75),\n","    transforms.RandomResizedCrop(size=IMG_SIZE, scale=(1.0, 1.1)),\n","    # Phóng to trong khoảng 1.0–1.1x và resize về IMG_SIZE\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Thay đổi sáng/tương phản\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Warp đối xứng\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa ảnh màu RGB\n","])\n","# For validation/test: no augmentation\n","val_test_transforms = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Chuẩn hóa ảnh màu RGB\n","])\n","\n","# Chỉ dùng X sign rõ cấu trúc\n","train_dataset_clear = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='clear')\n","\n","# Hoặc chỉ dùng X sign biến dạng\n","train_dataset_deformed = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='deformed')\n","\n","# Hoặc dùng cả hai (mặc định)\n","train_dataset_both = FetalEchoDataset(main_folder, phase='train', transform=train_transforms, x_sign_mode='both')\n","\n","\n","# Load datasets\n","valid_dataset = FetalEchoDataset(main_folder, phase='valid', transform=val_test_transforms)\n","test_dataset  = FetalEchoDataset(main_folder, phase='test',  transform=val_test_transforms)\n","\n","# DataLoaders\n","BATCH_SIZE = 32\n","train_dataset_both_loader = DataLoader(train_dataset_both, batch_size=BATCH_SIZE, shuffle=True)\n","train_dataset_deformed_loader =DataLoader(train_dataset_deformed, batch_size=BATCH_SIZE, shuffle=True)\n","train_dataset_clear_loader = DataLoader(train_dataset_clear, batch_size=BATCH_SIZE, shuffle=True)\n","\n","valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcqdXTK8B61o","outputId":"00ec6cac-0013-47c1-f4f8-2be704f56724","executionInfo":{"status":"ok","timestamp":1747967280671,"user_tz":-420,"elapsed":6417717,"user":{"displayName":"Quyền Huỳnh Minh","userId":"18408894874296736455"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss = 0.9001, Train Acc = 0.6776, Val Loss = 0.5757, Val Acc = 0.8025, F1 Score (macro) = 0.6229\n","✅ Saved best model!\n","Epoch 2: Train Loss = 0.4300, Train Acc = 0.8516, Val Loss = 0.5086, Val Acc = 0.8314, F1 Score (macro) = 0.7313\n","✅ Saved best model!\n","Epoch 3: Train Loss = 0.3139, Train Acc = 0.8877, Val Loss = 0.8022, Val Acc = 0.7996, F1 Score (macro) = 0.6704\n","Epoch 4: Train Loss = 0.2868, Train Acc = 0.8995, Val Loss = 0.4834, Val Acc = 0.8661, F1 Score (macro) = 0.7856\n","✅ Saved best model!\n","Epoch 5: Train Loss = 0.3061, Train Acc = 0.8962, Val Loss = 0.4841, Val Acc = 0.8432, F1 Score (macro) = 0.7092\n","Epoch 6: Train Loss = 0.2930, Train Acc = 0.9020, Val Loss = 0.4545, Val Acc = 0.8521, F1 Score (macro) = 0.7602\n","Epoch 7: Train Loss = 0.2508, Train Acc = 0.9110, Val Loss = 0.5261, Val Acc = 0.8506, F1 Score (macro) = 0.7523\n","Epoch 8: Train Loss = 0.2491, Train Acc = 0.9173, Val Loss = 0.4298, Val Acc = 0.8743, F1 Score (macro) = 0.8057\n","✅ Saved best model!\n","Epoch 9: Train Loss = 0.2286, Train Acc = 0.9175, Val Loss = 0.5033, Val Acc = 0.8661, F1 Score (macro) = 0.7533\n","Epoch 10: Train Loss = 0.2314, Train Acc = 0.9235, Val Loss = 0.6669, Val Acc = 0.8158, F1 Score (macro) = 0.7501\n","Epoch 11: Train Loss = 0.1705, Train Acc = 0.9406, Val Loss = 1.0131, Val Acc = 0.6827, F1 Score (macro) = 0.6557\n","Epoch 12: Train Loss = 0.1571, Train Acc = 0.9471, Val Loss = 0.3253, Val Acc = 0.8987, F1 Score (macro) = 0.8398\n","✅ Saved best model!\n","Epoch 13: Train Loss = 0.1555, Train Acc = 0.9466, Val Loss = 0.4372, Val Acc = 0.8861, F1 Score (macro) = 0.8261\n","Epoch 14: Train Loss = 0.1378, Train Acc = 0.9534, Val Loss = 0.4933, Val Acc = 0.8706, F1 Score (macro) = 0.7917\n","Epoch 15: Train Loss = 0.1325, Train Acc = 0.9579, Val Loss = 0.4709, Val Acc = 0.8395, F1 Score (macro) = 0.7499\n","Epoch 16: Train Loss = 0.1071, Train Acc = 0.9611, Val Loss = 0.4737, Val Acc = 0.8587, F1 Score (macro) = 0.7850\n","Epoch 17: Train Loss = 0.1065, Train Acc = 0.9657, Val Loss = 0.2042, Val Acc = 0.9283, F1 Score (macro) = 0.8774\n","✅ Saved best model!\n","Epoch 18: Train Loss = 0.0916, Train Acc = 0.9689, Val Loss = 0.2762, Val Acc = 0.9142, F1 Score (macro) = 0.8261\n","Epoch 19: Train Loss = 0.0870, Train Acc = 0.9687, Val Loss = 0.2981, Val Acc = 0.9090, F1 Score (macro) = 0.8523\n","Epoch 20: Train Loss = 0.0596, Train Acc = 0.9799, Val Loss = 0.2734, Val Acc = 0.9238, F1 Score (macro) = 0.8571\n","Epoch 21: Train Loss = 0.0700, Train Acc = 0.9782, Val Loss = 0.2911, Val Acc = 0.9127, F1 Score (macro) = 0.8561\n","Epoch 22: Train Loss = 0.0450, Train Acc = 0.9855, Val Loss = 0.1974, Val Acc = 0.9312, F1 Score (macro) = 0.8544\n","Epoch 23: Train Loss = 0.0349, Train Acc = 0.9890, Val Loss = 0.2421, Val Acc = 0.9223, F1 Score (macro) = 0.8617\n","Epoch 24: Train Loss = 0.0312, Train Acc = 0.9895, Val Loss = 0.1915, Val Acc = 0.9371, F1 Score (macro) = 0.8928\n","✅ Saved best model!\n","Epoch 25: Train Loss = 0.0211, Train Acc = 0.9922, Val Loss = 0.2349, Val Acc = 0.9334, F1 Score (macro) = 0.8816\n","Epoch 26: Train Loss = 0.0133, Train Acc = 0.9965, Val Loss = 0.1653, Val Acc = 0.9460, F1 Score (macro) = 0.9050\n","✅ Saved best model!\n","Epoch 27: Train Loss = 0.0172, Train Acc = 0.9952, Val Loss = 0.1926, Val Acc = 0.9357, F1 Score (macro) = 0.8864\n","Epoch 28: Train Loss = 0.0096, Train Acc = 0.9972, Val Loss = 0.1807, Val Acc = 0.9393, F1 Score (macro) = 0.8932\n","Epoch 29: Train Loss = 0.0098, Train Acc = 0.9982, Val Loss = 0.2081, Val Acc = 0.9364, F1 Score (macro) = 0.8903\n","Epoch 30: Train Loss = 0.0104, Train Acc = 0.9970, Val Loss = 0.2110, Val Acc = 0.9342, F1 Score (macro) = 0.8881\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from sklearn.metrics import f1_score\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","# Device & model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = models.densenet201(num_classes=len(classes)).to(device)\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimizer & scheduler\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","num_epochs = 30\n","steps_per_epoch = len(train_dataset_both_loader)\n","scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=steps_per_epoch, epochs=num_epochs)\n","\n","# Tracking\n","train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n","best_f1 = 0.0\n","pathbestmodel = ''\n","count = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct_train, total_train = 0.0, 0, 0\n","\n","    for inputs, labels in train_dataset_both_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","\n","    epoch_loss = running_loss / len(train_dataset_both_loader.dataset)\n","    train_acc = correct_train / total_train\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(train_acc)\n","\n","    # Validation\n","    model.eval()\n","    valid_loss, correct_val = 0.0, 0\n","    all_preds, all_labels = [], []\n","\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct_val += (preds == labels).sum().item()\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    valid_epoch_loss = valid_loss / len(valid_loader.dataset)\n","    val_acc = correct_val / len(valid_loader.dataset)\n","    f1 = f1_score(all_labels, all_preds, average='macro')\n","\n","    valid_losses.append(valid_epoch_loss)\n","    valid_accuracies.append(val_acc)\n","\n","    print(f\"Epoch {epoch+1}: \"\n","          f\"Train Loss = {epoch_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n","          f\"Val Loss = {valid_epoch_loss:.4f}, Val Acc = {val_acc:.4f}, \"\n","          f\"F1 Score (macro) = {f1:.4f}\")\n","\n","    # Save best model\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        pathbestmodel = f'/content/drive/MyDrive/Colab Notebooks/model/model_test/DenseNet201_bestweight_{count}.pt'\n","        torch.save(model.state_dict(), pathbestmodel)\n","        count += 1\n","        print(\"✅ Saved best model!\")"]},{"cell_type":"code","source":[],"metadata":{"id":"vcTx1ETIVUsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","print(\"Classification Report:\")\n","print(classification_report(all_labels, all_preds, target_names=classes))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(all_labels, all_preds))"],"metadata":{"id":"ra45ulBSEdQd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747967280705,"user_tz":-420,"elapsed":21,"user":{"displayName":"Quyền Huỳnh Minh","userId":"18408894874296736455"}},"outputId":"34cd013c-a05c-4d9d-8da9-416f26d9af69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","       Aorta       0.71      0.96      0.82        96\n","       Flows       0.99      0.99      0.99       175\n","       Other       0.97      0.95      0.96       628\n","      V sign       0.98      0.93      0.95       362\n","      X sign       0.74      0.70      0.72        91\n","\n","    accuracy                           0.93      1352\n","   macro avg       0.88      0.91      0.89      1352\n","weighted avg       0.94      0.93      0.94      1352\n","\n","Confusion Matrix:\n","[[ 92   0   1   0   3]\n"," [  0 173   2   0   0]\n"," [ 20   1 597   6   4]\n"," [  0   0   9 337  16]\n"," [ 17   0   8   2  64]]\n"]}]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Giả sử bạn đã có:\n","# - mô hình: model\n","# - tập test: test_loader\n","# - thiết bị: device (CPU hoặc GPU)\n","\n","model.eval()  # chế độ đánh giá\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():  # không cần gradient\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","\n","# ✅ In kết quả đánh giá\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true, y_pred, target_names=classes))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_true, y_pred))\n"],"metadata":{"id":"D2-rWTVBFZcd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747967800402,"user_tz":-420,"elapsed":519695,"user":{"displayName":"Quyền Huỳnh Minh","userId":"18408894874296736455"}},"outputId":"e87612e1-c110-452e-a3b3-3d3ef3d5e9ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","       Aorta       0.86      0.86      0.86       133\n","       Flows       1.00      0.98      0.99       219\n","       Other       0.96      0.97      0.96       689\n","      V sign       0.96      0.90      0.93       259\n","      X sign       0.71      0.87      0.78        79\n","\n","    accuracy                           0.94      1379\n","   macro avg       0.90      0.92      0.91      1379\n","weighted avg       0.94      0.94      0.94      1379\n","\n","Confusion Matrix:\n","[[115   0  12   0   6]\n"," [  0 215   4   0   0]\n"," [ 11   0 665   4   9]\n"," [  7   0   7 232  13]\n"," [  0   0   4   6  69]]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1_AmhJ9iiL-TQbVhJN-P72q4ddaf7QsjZ","timestamp":1747556476854}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}